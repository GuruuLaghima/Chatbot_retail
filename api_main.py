from fastapi import FastAPI, HTTPException, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import HTMLResponse
from pydantic import BaseModel, validator
from typing import List, Dict, Optional
import json
import logging
from datetime import datetime
import os
from pathlib import Path

# Import avec gestion d'erreur
try:
    from ml_pipeline import OptimizedFashionChatbot
except ImportError as e:
    print(f"‚ùå Erreur import ML pipeline: {e}")
    raise

# Configuration du logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Mod√®les Pydantic simplifi√©s
class ChatMessage(BaseModel):
    message: str
    user_id: Optional[str] = "anonymous"
    session_id: Optional[str] = "default"

class ChatResponse(BaseModel):
    success: bool
    intent: Optional[str] = None
    confidence: Optional[float] = None
    entities: Optional[Dict] = None
    response: str
    recommended_products: Optional[List[Dict]] = None
    timestamp: str

# Fonction de r√©solution de chemins simplifi√©e
def find_data_file(filename: str) -> str:
    """Trouve un fichier de donn√©es dans diff√©rents emplacements"""
    possible_paths = [
        filename,
        f"data/{filename}",
        f"../data/{filename}"
    ]
    
    for path in possible_paths:
        if os.path.exists(path):
            print(f"‚úÖ Fichier trouv√©: {path}")
            return path
    
    raise FileNotFoundError(f"‚ùå Fichier '{filename}' introuvable")

# Initialisation FastAPI
app = FastAPI(
    title="Chanel Maison Heritage - Chatbot API",
    description="API intelligente pour conseillers de vente",
    version="2.0.1"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Variables globales
chatbot_ml = None
products_data = None

# Startup event corrig√©
@app.on_event("startup")
async def startup_event():
    """Initialisation corrig√©e au d√©marrage"""
    global chatbot_ml, products_data
    
    logger.info("üöÄ D√©marrage API Chanel Maison Heritage...")
    
    try:
        # Chargement des donn√©es produits
        products_path = find_data_file("products.json")
        with open(products_path, 'r', encoding='utf-8') as f:
            products_data = json.load(f)
        logger.info(f"‚úÖ Produits charg√©s: {len(products_data.get('products', []))}")
        
        # Initialisation du mod√®le ML
        chatbot_ml = OptimizedFashionChatbot()
        
        # Tentative de chargement d'un mod√®le pr√©-entra√Æn√©
        model_path = "fashion_chatbot_optimized.pkl"
        if os.path.exists(model_path):
            try:
                chatbot_ml.load_model(model_path)
                logger.info("‚úÖ Mod√®le pr√©-entra√Æn√© charg√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  √âchec chargement mod√®le: {e}")
                logger.info("üîÑ Entra√Ænement du nouveau mod√®le...")
                await train_new_model()
        else:
            logger.info("üîÑ Entra√Ænement du mod√®le...")
            await train_new_model()
        
        logger.info("‚úÖ API pr√™te !")
        
    except Exception as e:
        logger.error(f"‚ùå Erreur au d√©marrage: {e}")
        # Ne pas lever l'exception pour permettre √† l'API de d√©marrer

async def train_new_model():
    """Entra√Ænement du mod√®le avec gestion d'erreur"""
    try:
        training_path = find_data_file("training_data.json")
        products_path = find_data_file("products.json")
        
        results = chatbot_ml.train_full_pipeline(training_path, products_path)
        
        # Gestion flexible des cl√©s de r√©sultat
        if results.get('status') == 'optimized_success':
            intent_results = results.get('intent_classification', {})
            
            # Essai de diff√©rentes cl√©s possibles
            accuracy = (intent_results.get('cv_accuracy') or 
                       intent_results.get('accuracy') or 
                       intent_results.get('best_score', 0))
            
            logger.info(f"‚úÖ Mod√®le entra√Æn√© - Pr√©cision: {accuracy:.3f}")
            
            # Sauvegarde
            try:
                chatbot_ml.save_model("fashion_chatbot_optimized.pkl")
                logger.info("üíæ Mod√®le sauvegard√©")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è  Sauvegarde √©chou√©e: {e}")
        else:
            logger.error(f"‚ùå √âchec entra√Ænement: {results.get('error', 'Erreur inconnue')}")
            
    except Exception as e:
        logger.error(f"‚ùå Erreur entra√Ænement: {e}")

# Routes principales
@app.get("/", response_class=HTMLResponse)
async def root():
    """Interface web am√©lior√©e pour conseillers"""
    try:
        with open('app.html', 'r', encoding='utf-8') as f:
            return f.read()
    except FileNotFoundError:
        return "<h1>Erreur: Interface non trouv√©e</h1>"

@app.post("/api/chat", response_model=ChatResponse)
async def chat_endpoint(message: ChatMessage):
    """Endpoint principal pour le chat"""
    try:
        if not chatbot_ml:
            return ChatResponse(
                success=False,
                response="Service en cours d'initialisation, veuillez patienter...",
                timestamp=datetime.now().isoformat()
            )
        
        # Traitement de la requ√™te
        result = chatbot_ml.process_query(message.message)
        
        return ChatResponse(
            success=result.get('success', True),
            intent=result.get('intent'),
            confidence=result.get('confidence'),
            entities=result.get('entities'),
            response=result.get('response', result.get('fallback_response', 'D√©sol√©, je n\'ai pas compris.')),
            recommended_products=result.get('recommended_products', []),
            timestamp=datetime.now().isoformat()
        )
        
    except Exception as e:
        logger.error(f"Erreur dans chat_endpoint: {e}")
        return ChatResponse(
            success=False,
            response="Une erreur technique est survenue.",
            timestamp=datetime.now().isoformat()
        )

@app.get("/health")
async def health_check():
    """V√©rification de sant√©"""
    return {
        "status": "healthy" if chatbot_ml else "initializing",
        "timestamp": datetime.now().isoformat(),
        "ml_model": "loaded" if chatbot_ml and hasattr(chatbot_ml, 'intent_classifier') else "loading",
        "products": "loaded" if products_data else "not_loaded"
    }

@app.get("/api/stats")
async def get_stats():
    """Statistiques de l'API"""
    return {
        "status": "operational",
        "model_loaded": chatbot_ml is not None,
        "products_count": len(products_data.get('products', [])) if products_data else 0,
        "timestamp": datetime.now().isoformat()
    }

# Point d'entr√©e
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "api_main:app", 
        host="0.0.0.0", 
        port=8000, 
        reload=True,
        log_level="info"
    )