import json
import re
import pickle
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
import random

# ML Libraries optimisÃ©es
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from sklearn.preprocessing import LabelEncoder
from sklearn.pipeline import Pipeline

# NLP Libraries
import nltk
from nltk.corpus import stopwords
from nltk.stem import SnowballStemmer

# Download required NLTK data
try:
    nltk.data.find('corpora/stopwords')
except LookupError:
    nltk.download('stopwords')

@dataclass
class PredictionResult:
    """Structure pour les rÃ©sultats de prÃ©diction"""
    intent: str
    confidence: float
    entities: Dict[str, str]
    response_template: str

class OptimizedTextPreprocessor:
    """Preprocessing ultra-optimisÃ© pour le franÃ§ais"""
    
    def __init__(self):
        self.french_stopwords = set(stopwords.words('french'))
        
        # Stopwords Ã  ne pas filtrer pour la mode
        self.preserve_words = {
            'sac', 'sur', 'en', 'de', 'du', 'le', 'la', 'un', 'une',
            'pour', 'avec', 'sans', 'trÃ¨s', 'bien', 'bon', 'belle'
        }
        
        # Filtrage intelligent des stopwords
        self.filtered_stopwords = self.french_stopwords - self.preserve_words
        
        # Mots fashion cruciaux Ã  prÃ©server
        self.fashion_keywords = {
            # Produits
            'tailleur', 'robe', 'sac', 'sacoche', 'maroquinerie',
            'chaussure', 'chaussures', 'escarpin', 'escarpins', 'ballerine', 'ballerines',
            'manteau', 'veste', 'bijou', 'bijoux', 'collier', 'bracelet',
            
            # MatiÃ¨res
            'tweed', 'cuir', 'agneau', 'soie', 'satin', 'matelasse', 'boucle',
            'laine', 'coton', 'perle', 'perles', 'metal',
            
            # Couleurs
            'noir', 'blanc', 'rouge', 'beige', 'marine', 'camel', 'gris', 'rose',
            'vert', 'bleu', 'dore', 'argente', 'multicolore', 'nude',
            
            # Occasions
            'business', 'bureau', 'travail', 'professionnel',
            'soiree', 'cocktail', 'gala', 'mariage', 'ceremonie',
            'quotidien', 'decontracte', 'casual', 'ville',
            
            # Actions/Verbes fashion
            'cherche', 'chercher', 'voudrais', 'veux', 'besoin',
            'recommande', 'conseille', 'suggere',
            'disponible', 'stock', 'inventaire',
            'prix', 'cout', 'tarif', 'budget',
            'entretien', 'nettoyer', 'soin', 'maintenance',
            
            # Marque/Style
            'chanel', 'heritage', 'maison', 'collection',
            'elegant', 'moderne', 'classique', 'iconique',
            'luxe', 'haut', 'gamme', 'prestige'
        }
        
        # Patterns d'entitÃ©s amÃ©liorÃ©s
        self.entity_patterns = {
            'size': r'\b(3[4-8]|4[0-6]|small|medium|large|s|m|l|xl|petite?|grande?|taille)\b',
            'color': r'\b(noir|blanc|rouge|beige|marine|camel|rose|gris|bleu|vert|dore|argente|multicolore|nude)\w*\b',
            'price': r'\b(\d+[â‚¬$]|\d+\s*euros?|prix|cout|tarif|budget|montant)\b',
            'product_id': r'\b(CMH\d{3})\b',
            'occasion': r'\b(bureau|soiree|cocktail|mariage|business|quotidien|gala|decontracte|travail|ceremonie)\b',
            'material': r'\b(cuir|tweed|soie|satin|laine|agneau|perles?|metal|coton|matelasse)\b',
            'brand': r'\b(chanel|heritage|maison)\b',
            'location': r'\b(paris|lyon|cannes|france|magasin|boutique|entrepot)\b',
            'product_type': r'\b(sac|chaussure|robe|tailleur|manteau|veste|bijou|collier|escarpin|ballerine)\w*\b'
        }
    
    def clean_and_normalize(self, text: str) -> str:
        """Nettoyage optimisÃ©"""
        if not text:
            return ""
        
        text = text.lower()
        
        #  Normalisation franÃ§aise simplifiÃ©e
        replacements = {
            'Ã ': 'a', 'Ã¢': 'a', 'Ã¤': 'a', 'Ã¡': 'a',
            'Ã©': 'e', 'Ã¨': 'e', 'Ãª': 'e', 'Ã«': 'e',
            'Ã®': 'i', 'Ã¯': 'i', 'Ã­': 'i',
            'Ã´': 'o', 'Ã¶': 'o', 'Ã³': 'o',
            'Ã¹': 'u', 'Ã»': 'u', 'Ã¼': 'u', 'Ãº': 'u',
            'Ã§': 'c', 'Ã±': 'n'
        }
        
        for accented, clean in replacements.items():
            text = text.replace(accented, clean)
        
        # Nettoyage doux
        text = re.sub(r'[^\w\s\'-]', ' ', text)
        text = re.sub(r'\s+', ' ', text).strip()
        
        return text
    
    def extract_entities(self, text: str) -> Dict[str, List[str]]:
        """Extraction d'entitÃ©s robuste"""
        entities = {}
        text_clean = self.clean_and_normalize(text)
        
        for entity_type, pattern in self.entity_patterns.items():
            matches = re.findall(pattern, text_clean, re.IGNORECASE)
            if matches:
                # DÃ©duplication et nettoyage
                unique_matches = list(set(match.strip() for match in matches if match.strip()))
                if unique_matches:
                    entities[entity_type] = unique_matches
        
        return entities
    
    def intelligent_tokenize(self, text: str) -> List[str]:
        """Tokenisation intelligente """
        clean_text = self.clean_and_normalize(text)
        tokens = clean_text.split()
        
        filtered_tokens = []
        for token in tokens:
            if token in self.fashion_keywords:
                # Garde ABSOLUMENT les mots fashion
                filtered_tokens.append(token)
            elif token in self.preserve_words:
                # Garde les mots courts importants
                filtered_tokens.append(token)
            elif token not in self.filtered_stopwords and len(token) >= 2:
                #  Seuil rÃ©duit Ã  2 caractÃ¨res
                filtered_tokens.append(token)
        
        return filtered_tokens
    
    def preprocess_for_ml(self, text: str) -> str:
        """Preprocessing final pour ML"""
        tokens = self.intelligent_tokenize(text)
        return ' '.join(tokens)

class OptimizedIntentClassifier:
    """Classificateur"""
    
    def __init__(self):
        self.preprocessor = OptimizedTextPreprocessor()
        
        # TF-IDF optimisÃ© pour petit dataset
        self.vectorizer = TfidfVectorizer(
            max_features=1500,      
            ngram_range=(1, 2),     
            min_df=1,               
            max_df=0.85,            
            analyzer='word',
            lowercase=True,
            strip_accents='unicode',
            token_pattern=r'\b[a-zA-Z]{2,}\b',
            sublinear_tf=True
        )
        
        # ModÃ¨les mieux configurÃ©s
        self.models = {
            'logistic': LogisticRegression(
                C=0.5,                   
                max_iter=1000,
                class_weight='balanced',
                random_state=42,
                solver='liblinear'        
            ),
            'svm_linear': SVC(
                kernel='linear',
                C=0.8,                    
                probability=True,
                class_weight='balanced',
                random_state=42
            ),
            'random_forest': RandomForestClassifier(
                n_estimators=150,        
                max_depth=8,              
                min_samples_split=3,     
                min_samples_leaf=2,
                class_weight='balanced',
                random_state=42
            )
        }
        
        self.best_model = None
        self.best_model_name = None
        self.label_encoder = LabelEncoder()
        self.is_trained = False
    
    def prepare_data(self, training_data: List[Dict]) -> Tuple[np.ndarray, np.ndarray]:
        """PrÃ©paration robuste des donnÃ©es"""
        texts = []
        labels = []
        
        for example in training_data:
            if 'text' in example and 'intent' in example:
                processed_text = self.preprocessor.preprocess_for_ml(example['text'])
                if processed_text.strip(): 
                    texts.append(processed_text)
                    labels.append(example['intent'])
        
        return np.array(texts), np.array(labels)
    
    def train(self, training_data: List[Dict]) -> Dict[str, float]:
        """EntraÃ®nement robuste avec validation croisÃ©e"""
        print("ğŸ¤– EntraÃ®nement optimisÃ© du classificateur...")
        
        # PrÃ©paration des donnÃ©es
        X_text, y = self.prepare_data(training_data)
        
        print(f"ğŸ“Š DonnÃ©es: {len(X_text)} exemples, {len(set(y))} classes")
        print(f"ğŸ“Š Classes: {list(set(y))}")
        
        #VÃ©rification des donnÃ©es
        if len(X_text) == 0:
            raise ValueError("Aucune donnÃ©e valide aprÃ¨s preprocessing!")
        
        # Encodage des labels
        y_encoded = self.label_encoder.fit_transform(y)
        
        # Vectorisation
        X_vectorized = self.vectorizer.fit_transform(X_text)
        print(f"ğŸ“Š Features TF-IDF: {X_vectorized.shape}")
        
        # Validation croisÃ©e pour sÃ©lection robuste
        model_scores = {}
        model_cv_scores = {}
        trained_models = {}
        
        for model_name, model in self.models.items():
            print(f"   ğŸ”¬ Test {model_name} avec validation croisÃ©e...")
            
            # Validation croisÃ©e stratifiÃ©e
            try:
                cv_scores = cross_val_score(
                    model, X_vectorized, y_encoded, 
                    cv=3, scoring='accuracy', n_jobs=-1
                )
                mean_cv_score = cv_scores.mean()
                model_cv_scores[model_name] = mean_cv_score
                
                # EntraÃ®nement sur tout le dataset
                model.fit(X_vectorized, y_encoded)
                trained_models[model_name] = model
                
                print(f"      âœ… {model_name}: CV={mean_cv_score:.3f} (Â±{cv_scores.std():.3f})")
                
            except Exception as e:
                print(f"      âŒ {model_name}: Erreur - {e}")
                model_cv_scores[model_name] = 0.0
        
        # SÃ©lection basÃ©e sur validation croisÃ©e
        if model_cv_scores:
            self.best_model_name = max(model_cv_scores, key=model_cv_scores.get)
            self.best_model = trained_models[self.best_model_name]
            best_score = model_cv_scores[self.best_model_name]
        else:
            raise ValueError("Aucun modÃ¨le n'a pu Ãªtre entraÃ®nÃ©!")
        
        print(f"ğŸ† Meilleur: {self.best_model_name} (CV: {best_score:.3f})")
        
        self.is_trained = True
        
        return {
            'best_model': self.best_model_name,
            'cv_accuracy': best_score,
            'all_cv_scores': model_cv_scores
        }
    
    def predict(self, text: str) -> PredictionResult:
        """PrÃ©diction robuste"""
        if not self.is_trained:
            raise ValueError("ModÃ¨le non entraÃ®nÃ©!")
        
        # Preprocessing
        processed_text = self.preprocessor.preprocess_for_ml(text)
        
        # Gestion des textes vides
        if not processed_text.strip():
            return PredictionResult(
                intent='general_chat',
                confidence=0.5,
                entities={},
                response_template="Je n'ai pas bien compris, pouvez-vous reformuler ?"
            )
        
        entities = self.preprocessor.extract_entities(text)
        
        # Vectorisation
        X = self.vectorizer.transform([processed_text])
        
        # PrÃ©diction
        try:
            predicted_label = self.best_model.predict(X)[0]
            
            # Confiance
            if hasattr(self.best_model, 'predict_proba'):
                probabilities = self.best_model.predict_proba(X)[0]
                confidence = probabilities.max()
            else:
                confidence = 0.8
            
            # DÃ©codage
            intent = self.label_encoder.inverse_transform([predicted_label])[0]
            
            return PredictionResult(
                intent=intent,
                confidence=confidence,
                entities=entities,
                response_template=f"Intent: {intent}"
            )
            
        except Exception as e:
            print(f"âŒ Erreur prÃ©diction: {e}")
            return PredictionResult(
                intent='general_chat',
                confidence=0.3,
                entities={},
                response_template="Erreur lors de l'analyse de votre demande."
            )

class RobustSemanticSearch:
    """Recherche sÃ©mantique """
    
    def __init__(self):
        print("ğŸ” Initialisation recherche sÃ©mantique robuste...")
        
        self.model = None
        self.use_semantic = False
        
        # Essai de plusieurs modÃ¨les avec fallback
        models_to_try = [
            'paraphrase-multilingual-MiniLM-L12-v2',
            'distiluse-base-multilingual-cased',
            'all-MiniLM-L6-v2'
        ]
        
        for model_name in models_to_try:
            try:
                from sentence_transformers import SentenceTransformer
                self.model = SentenceTransformer(model_name)
                self.use_semantic = True
                print(f"âœ… ModÃ¨le {model_name} chargÃ© avec succÃ¨s")
                break
            except Exception as e:
                print(f"âš ï¸  Tentative {model_name} Ã©chouÃ©e: {e}")
                continue
        
        if not self.use_semantic:
            print("ğŸ“ Mode recherche textuelle uniquement")
        
        self.product_embeddings = None
        self.products_df = None
        
    def index_products(self, products_data: List[Dict]):
        """Indexation robuste"""
        print("ğŸ” Indexation des produits...")
        
        self.products_df = pd.DataFrame(products_data)
        
        if not self.use_semantic:
            print("ğŸ“ Indexation textuelle uniquement")
            return
        
        # Descriptions enrichies et mieux structurÃ©es
        descriptions = []
        for product in products_data:
            # Composition intelligente de la description
            parts = []
            
            # Nom et catÃ©gorie (prioritÃ© haute)
            name = product.get('name', '')
            category = product.get('category', '')
            subcategory = product.get('subcategory', '')
            
            if name:
                parts.append(name)
            if category:
                parts.append(category)
            if subcategory:
                parts.append(subcategory)
            
            # Description
            description = product.get('description', '')
            if description:
                parts.append(description)
            
            # MatÃ©riaux et couleurs
            materials = product.get('materials', [])
            colors = product.get('colors', [])
            occasions = product.get('occasions', [])
            
            if materials:
                parts.append(' '.join(materials))
            if colors:
                parts.append(' '.join(colors))
            if occasions:
                parts.append(' '.join(occasions))
            
            # Style et tags
            style_profile = product.get('style_profile', [])
            tags = product.get('tags', [])
            
            if style_profile:
                parts.append(' '.join(style_profile))
            if tags:
                parts.append(' '.join(tags))
            
            description = ' '.join(filter(None, parts))
            descriptions.append(description)
        
        try:
            if self.model:
                self.product_embeddings = self.model.encode(descriptions, show_progress_bar=True)
                print(f"   âœ… {len(products_data)} produits indexÃ©s avec embeddings")
        except Exception as e:
            print(f"   âš ï¸  Erreur indexation sÃ©mantique: {e}")
            self.product_embeddings = None
            self.use_semantic = False
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """Recherche hybride robuste"""
        if self.products_df is None or len(self.products_df) == 0:
            return []
        
        # Recherche sÃ©mantique avec fallback robuste
        if self.use_semantic and self.product_embeddings is not None:
            try:
                return self._semantic_search(query, top_k)
            except Exception as e:
                print(f"âš ï¸  Recherche sÃ©mantique Ã©chouÃ©e: {e}, fallback textuel")
                return self._enhanced_keyword_search(query, top_k)
        
        # Recherche textuelle amÃ©liorÃ©e
        return self._enhanced_keyword_search(query, top_k)
    
    def _semantic_search(self, query: str, top_k: int) -> List[Dict]:
        """Recherche sÃ©mantique robuste"""
        if not self.model:
            raise ValueError("ModÃ¨le sÃ©mantique non disponible")
        
        query_embedding = self.model.encode([query])
        
        from sklearn.metrics.pairwise import cosine_similarity
        similarities = cosine_similarity(query_embedding, self.product_embeddings)[0]
        
        # Seuil adaptatif
        mean_similarity = similarities.mean()
        std_similarity = similarities.std()
        threshold = max(0.1, mean_similarity - 0.5 * std_similarity)
        
        # Top rÃ©sultats avec seuil intelligent
        top_indices = similarities.argsort()[-top_k*2:][::-1]  # Prend plus pour filtrer
        
        results = []
        for idx in top_indices:
            if similarities[idx] > threshold and len(results) < top_k:
                product = self.products_df.iloc[idx].to_dict()
                product['similarity_score'] = float(similarities[idx])
                results.append(product)
        
        return results
    
    def _enhanced_keyword_search(self, query: str, top_k: int) -> List[Dict]:
        """Recherche textuelle intelligente """
        query_lower = query.lower().strip()
        if not query_lower:
            return []
        
        results = []
        
        # Mots-clÃ©s Ã©tendus et plus prÃ©cis
        enhanced_keywords = {
            'sac': ['sac', 'sacoche', 'maroquinerie', 'cabas', 'pochette', 'besace', 'cartable'],
            'chaussure': ['chaussure', 'chaussures', 'escarpin', 'escarpins', 'ballerine', 'ballerines', 'soulier', 'souliers', 'chaussant'],
            'robe': ['robe', 'robes', 'dress'],
            'tailleur': ['tailleur', 'tailleurs', 'costume', 'suit', 'ensemble'],
            'bijou': ['bijou', 'bijoux', 'collier', 'colliers', 'bracelet', 'bague', 'perle', 'perles', 'jewelry'],
            'manteau': ['manteau', 'manteaux', 'veste', 'vestes', 'blouson', 'coat', 'jacket'],
            'vetement': ['vetement', 'vetements', 'habit', 'habits', 'tenue', 'pret-a-porter']
        }
        
        # Score plus nuancÃ©
        for _, product in self.products_df.iterrows():
            score = 0
            product_dict = product.to_dict()
            
            # Texte du produit en minuscules
            product_texts = {
                'name': product_dict.get('name', '').lower(),
                'category': product_dict.get('category', '').lower(),
                'subcategory': product_dict.get('subcategory', '').lower(),
                'description': product_dict.get('description', '').lower(),
                'materials': ' '.join(product_dict.get('materials', [])).lower(),
                'colors': ' '.join(product_dict.get('colors', [])).lower(),
                'occasions': ' '.join(product_dict.get('occasions', [])).lower(),
                'tags': ' '.join(product_dict.get('tags', [])).lower()
            }
            
            all_product_text = ' '.join(product_texts.values())
            
            # Correspondance par catÃ©gorie avec poids
            category_match_found = False
            for category, keywords in enhanced_keywords.items():
                if any(kw in query_lower for kw in keywords):
                    # VÃ©rifier correspondance dans les textes produit
                    for field, text in product_texts.items():
                        if any(kw in text for kw in keywords):
                            # Poids selon l'importance du champ
                            field_weights = {
                                'name': 15, 'category': 12, 'subcategory': 10,
                                'description': 8, 'tags': 6, 'materials': 4,
                                'colors': 3, 'occasions': 5
                            }
                            score += field_weights.get(field, 2)
                            category_match_found = True
            
            #  Correspondance de mots individuels
            query_words = [w for w in query_lower.split() if len(w) > 1]
            for word in query_words:
                if word in all_product_text:
                    # Bonus selon le contexte
                    if word in product_texts['name']:
                        score += 8
                    elif word in product_texts['category'] or word in product_texts['subcategory']:
                        score += 6
                    elif word in product_texts['description']:
                        score += 4
                    else:
                        score += 2
            
            # Bonus pour correspondance multi-mots
            if len(query_words) > 1:
                words_found = sum(1 for word in query_words if word in all_product_text)
                coverage = words_found / len(query_words)
                score += coverage * 5
            
            #  Bonus pour correspondance exacte d'expressions
            if len(query_lower) > 3 and query_lower in all_product_text:
                score += 10
            
            if score > 0:
                # Normalisation du score
                max_possible_score = 50  # Score thÃ©orique maximum
                normalized_score = min(score / max_possible_score, 1.0)
                product_dict['similarity_score'] = normalized_score
                results.append(product_dict)
        
        # Tri par score dÃ©croissant
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return results[:top_k]

class OptimizedFashionChatbot:
    """Chatbot fashion ultra-optimisÃ© et fiable"""
    
    def __init__(self):
        self.intent_classifier = OptimizedIntentClassifier()
        self.semantic_search = RobustSemanticSearch()
        
    def load_training_data(self, training_file: str) -> Dict:
        """Chargement robuste des donnÃ©es"""
        try:
            with open(training_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… DonnÃ©es d'entraÃ®nement chargÃ©es: {len(data.get('training_data', []))} exemples")
            return data
        except Exception as e:
            print(f"âŒ Erreur chargement training data: {e}")
            raise
    
    def load_products_data(self, products_file: str) -> Dict:
        """Chargement robuste des produits"""
        try:
            with open(products_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            print(f"âœ… DonnÃ©es produits chargÃ©es: {len(data.get('products', []))} produits")
            return data
        except Exception as e:
            print(f"âŒ Erreur chargement products data: {e}")
            raise
    
    def train_full_pipeline(self, training_file: str, products_file: str) -> Dict:
        """Pipeline d'entraÃ®nement ultra-robuste"""
        print("âš¡ TF-IDF + Validation CroisÃ©e + Recherche hybride robuste")
        
        try:
            # Chargement des donnÃ©es
            training_data = self.load_training_data(training_file)
            products_data = self.load_products_data(products_file)
            
            # Validation des donnÃ©es
            if not training_data.get('training_data'):
                raise ValueError("Aucune donnÃ©e d'entraÃ®nement trouvÃ©e!")
            if not products_data.get('products'):
                raise ValueError("Aucun produit trouvÃ©!")
            
            # EntraÃ®nement
            print("\nğŸ“š Phase d'entraÃ®nement...")
            training_results = self.intent_classifier.train(training_data['training_data'])
            
            # Indexation
            print("\nğŸ” Phase d'indexation...")
            self.semantic_search.index_products(products_data['products'])
            
            print("\nâœ… PIPELINE OPTIMISÃ‰ PRÃŠT !")
            print(f"ğŸ¯ PrÃ©cision CV: {training_results['cv_accuracy']:.1%}")
            print(f"ğŸ† Meilleur modÃ¨le: {training_results['best_model']}")
            
            return {
                'intent_classification': training_results,
                'products_indexed': len(products_data['products']),
                'semantic_search_enabled': self.semantic_search.use_semantic,
                'status': 'optimized_success'
            }
            
        except Exception as e:
            print(f"âŒ Erreur pipeline: {e}")
            return {
                'status': 'error',
                'error': str(e),
                'intent_classification': None,
                'products_indexed': 0
            }
    
    def process_query(self, user_query: str) -> Dict:
        """Traitement de requÃªte ultra-robuste"""
        try:
            # Validation d'entrÃ©e
            if not user_query or not user_query.strip():
                return {
                    'success': True,
                    'intent': 'general_chat',
                    'confidence': 0.5,
                    'entities': {},
                    'recommended_products': [],
                    'response': "Bonjour ! Comment puis-je vous aider aujourd'hui ?"
                }
            
            # Classification avec gestion d'erreur
            try:
                prediction = self.intent_classifier.predict(user_query)
            except Exception as e:
                print(f"âš ï¸  Erreur classification: {e}")
                return {
                    'success': False,
                    'error': f"Erreur classification: {e}",
                    'fallback_response': "DÃ©solÃ©, je n'ai pas pu analyser votre demande. Pouvez-vous reformuler ?"
                }
            
            # Recherche produits selon l'intention
            products = []
            if prediction.intent in ['product_search', 'style_recommendation', 'stock_check', 'price_inquiry']:
                try:
                    products = self.semantic_search.search(user_query, top_k=3)
                except Exception as e:
                    print(f"âš ï¸  Erreur recherche: {e}")
                    products = []
            
            #  RÃ©ponse structurÃ©e et robuste
            response = self._generate_enhanced_response(prediction, products, user_query)
            
            return {
                'success': True,
                'intent': prediction.intent,
                'confidence': prediction.confidence,
                'entities': prediction.entities,
                'recommended_products': products,
                'response': response,
                'debug_info': {
                    'processed_query': self.intent_classifier.preprocessor.preprocess_for_ml(user_query),
                    'search_enabled': self.semantic_search.use_semantic,
                    'products_found': len(products)
                }
            }
            
        except Exception as e:
            print(f"âŒ Erreur process_query: {e}")
            return {
                'success': False,
                'error': str(e),
                'fallback_response': "Une erreur technique s'est produite. Veuillez rÃ©essayer."
            }

    def _generate_enhanced_response(self, prediction: PredictionResult, products: List[Dict], query: str) -> str:
        """GÃ©nÃ©ration de rÃ©ponse intelligente et contextuelle - VERSION FINALE COMPLÃˆTE"""
        
        import random
        
        # Initialisation obligatoire de base_response
        base_response = ""
        
        # Templates de rÃ©ponses enrichis
        response_templates = {
            'general_chat': {
                'greetings': ['bonjour', 'salut', 'hello', 'bonsoir'],
                'thanks': ['merci', 'thank', 'remercie'],
                'goodbye': ['au revoir', 'bye', 'aurevoir', 'adieu'],
                'affirmative': ['oui', 'yes', 'parfait', 'ok', 'accord'],
                'negative': ['non', 'no', 'pas'],
                'polite': ['excusez', 'pardon', 'desolee', 'sil vous plait']
            },
            'product_search': [
                "Voici notre sÃ©lection exclusive qui pourrait vous intÃ©resser :",
                "J'ai trouvÃ© ces crÃ©ations Chanel parfaites pour vous :",
                "DÃ©couvrez ces piÃ¨ces iconiques de notre collection :"
            ],
            'price_inquiry': [
                "Voici les informations tarifaires demandÃ©es :",
                "Nos prix pour ces crÃ©ations :",
                "Budget nÃ©cessaire pour ces articles :"
            ],
            'stock_check': [
                "Ã‰tat actuel de nos stocks :",
                "DisponibilitÃ© en temps rÃ©el :",
                "VÃ©rification de notre inventaire :"
            ],
            'style_recommendation': [
                "Mes conseils de style personnalisÃ©s :",
                "Je recommande pour votre occasion :",
                "L'alliance parfaite pour vous :"
            ],
            'care_instructions': [
                "Conseils d'entretien de nos experts :",
                "Pour prÃ©server vos crÃ©ations Chanel :",
                "Instructions de soin recommandÃ©es :"
            ]
        }
        
        # DÃ©tection contextuelle
        query_lower = query.lower()
        
        if prediction.intent == 'general_chat':
            # DÃ©tection fine du contexte
            context_detected = False
            
            for context, keywords in response_templates['general_chat'].items():
                if any(kw in query_lower for kw in keywords):
                    if context == 'greetings':
                        base_response = "Bonjour et bienvenue chez Chanel Maison Heritage ! Comment puis-je vous accompagner dans votre recherche ?"
                    elif context == 'thanks':
                        base_response = "Je vous en prie ! C'est un plaisir de vous conseiller. Puis-je vous aider avec autre chose ?"
                    elif context == 'goodbye':
                        base_response = "Au revoir et merci de votre visite ! N'hÃ©sitez pas Ã  revenir pour dÃ©couvrir nos nouvelles crÃ©ations."
                    elif context == 'affirmative':
                        base_response = "Parfait ! Comment puis-je continuer Ã  vous assister ?"
                    elif context == 'negative':
                        base_response = "D'accord, puis-je vous proposer autre chose ou vous renseigner diffÃ©remment ?"
                    elif context == 'polite':
                        base_response = "Aucun souci ! Je suis lÃ  pour vous aider. Que puis-je faire pour vous ?"
                    context_detected = True
                    break
            
            if not context_detected:
                base_response = "Comment puis-je vous accompagner dans votre dÃ©couverte de nos crÃ©ations ?"
        
        elif prediction.intent == 'care_instructions':
            # Instructions d'entretien dÃ©taillÃ©es et spÃ©cifiques
            care_instructions = {
                'cuir': """
    **Entretien du cuir d'agneau Chanel :**
    â€¢ Nettoyage : Utilisez un chiffon doux lÃ©gÃ¨rement humide
    â€¢ Protection : Appliquez un produit hydratant spÃ©cial cuir tous les 3 mois
    â€¢ Stockage : Conservez dans un dustbag Ã  l'abri de la lumiÃ¨re
    â€¢ Ã‰vitez : L'eau, la chaleur directe et les produits chimiques
    â€¢ En cas de tache : Consultez immÃ©diatement nos experts en boutique""",
                
                'chaussures': """
    **Entretien spÃ©cialisÃ© pour chaussures Chanel :**
    â€¢ Nettoyage quotidien : Brossage dÃ©licat avec brosse en crin
    â€¢ Cirage : Utilisez un cirage de qualitÃ© adaptÃ© Ã  la couleur
    â€¢ Embauchoirs : InsÃ©rez des embauchoirs en bois aprÃ¨s chaque port
    â€¢ Rotation : Alternez vos paires pour laisser respirer le cuir
    â€¢ RÃ©paration : Faites ressemeler chez un cordonnier spÃ©cialisÃ©
    â€¢ Stockage : Conservez dans leur boÃ®te d'origine avec papier de soie""",
                
                'sac': """
    **Entretien des sacs en cuir Chanel :**
    â€¢ Nettoyage mensuel avec un chiffon microfibre lÃ©gÃ¨rement humide
    â€¢ Conditionnement du cuir tous les 3-4 mois avec un produit spÃ©cialisÃ©
    â€¢ Stockage dans le dustbag fourni, rempli de papier pour garder la forme
    â€¢ Ã‰vitez la surcharge pour prÃ©server la structure
    â€¢ Rotation des anses pour Ã©viter l'usure inÃ©gale""",
                
                'tweed': """
    **Entretien du tweed Chanel :**
    â€¢ Nettoyage Ã  sec uniquement chez un spÃ©cialiste textiles de luxe
    â€¢ Stockage sur cintre large pour prÃ©server la forme
    â€¢ Brossage dÃ©licat dans le sens du tissu avec une brosse Ã  vÃªtements
    â€¢ Protection anti-mites avec sachets naturels (lavande, cÃ¨dre)
    â€¢ Ã‰vitez l'exposition prolongÃ©e au soleil et Ã  l'humiditÃ©""",
                
                'soie': """
    **Entretien de la soie :**
    â€¢ Nettoyage Ã  sec professionnel obligatoire
    â€¢ Repassage Ã  tempÃ©rature douce (110Â°C max) avec un linge de protection
    â€¢ Stockage suspendu dans un endroit sec et aÃ©rÃ©
    â€¢ Ã‰vitez les parfums, dÃ©odorants et produits acides""",
                
                'perles': """
    **Entretien des perles de culture :**
    â€¢ Nettoyage aprÃ¨s chaque port avec un chiffon doux et sec
    â€¢ Ã‰vitez absolument le contact avec parfums, cosmÃ©tiques et transpiration
    â€¢ Stockage sÃ©parÃ© des autres bijoux dans une pochette douce
    â€¢ Enfilage Ã  vÃ©rifier annuellement chez un bijoutier"""
            }
            
            # SÃ©lection du template de base
            templates = response_templates.get('care_instructions', ["Conseils d'entretien :"])
            base_response = random.choice(templates)
            
            # DÃ©tection intelligente du matÃ©riau/produit
            material_found = None
            
            if any(word in query_lower for word in ['chaussure', 'chaussures', 'escarpin', 'ballerine', 'soulier']):
                material_found = 'chaussures'
            elif any(word in query_lower for word in ['sac', 'sacoche', 'maroquinerie']):
                material_found = 'sac'
            elif 'cuir' in query_lower:
                material_found = 'cuir'
            elif 'tweed' in query_lower:
                material_found = 'tweed'
            elif any(word in query_lower for word in ['soie', 'satin']):
                material_found = 'soie'
            elif any(word in query_lower for word in ['perle', 'perles', 'bijou', 'collier']):
                material_found = 'perles'
            
            if material_found and material_found in care_instructions:
                base_response += care_instructions[material_found]
            else:
                base_response += """
    **Conseils d'entretien gÃ©nÃ©raux pour vos crÃ©ations Chanel :**
    â€¢ Suivez toujours les Ã©tiquettes d'entretien spÃ©cifiques
    â€¢ PrivilÃ©giez le nettoyage professionnel pour les piÃ¨ces dÃ©licates
    â€¢ Stockez vos articles dans leurs dustbags d'origine
    â€¢ Ã‰vitez l'exposition directe Ã  la lumiÃ¨re et Ã  la chaleur
    â€¢ Consultez nos conseillers pour des instructions personnalisÃ©es"""
        
        elif prediction.intent == 'stock_check' and not products:
            # SÃ©lection du template de base
            templates = response_templates.get('stock_check', ["Ã‰tat de nos stocks :"])
            base_response = random.choice(templates)
            
            # Gestion complÃ¨te des stocks par localisation
            location_stocks = {
                'paris': {
                    'name': 'Paris Cambon',
                    'products': [
                        'Tailleur Tweed Iconique : 5 piÃ¨ces',
                        'Robe Satin AsymÃ©trique : 4 piÃ¨ces', 
                        'Sac MatelassÃ© ChaÃ®ne DorÃ©e : 6 piÃ¨ces',
                        'Escarpins Bout Rond : 8 piÃ¨ces',
                        'Collier Perles Signature : 8 piÃ¨ces',
                        'Ballerines Cuir Nude : 10 piÃ¨ces',
                        'Manteau BouclÃ© Long : 3 piÃ¨ces',
                        'Sac Cabas Grand Format : 4 piÃ¨ces'
                    ]
                },
                'lyon': {
                    'name': 'Lyon Presqu\'Ã®le',
                    'products': [
                        'Tailleur Tweed Iconique : 3 piÃ¨ces',
                        'Robe Satin AsymÃ©trique : 3 piÃ¨ces',
                        'Sac MatelassÃ© ChaÃ®ne DorÃ©e : 4 piÃ¨ces',
                        'Escarpins Bout Rond : 6 piÃ¨ces',
                        'Collier Perles Signature : 5 piÃ¨ces',
                        'Ballerines Cuir Nude : 8 piÃ¨ces',
                        'Manteau BouclÃ© Long : 2 piÃ¨ces',
                        'Sac Cabas Grand Format : 3 piÃ¨ces'
                    ]
                },
                'cannes': {
                    'name': 'Cannes Croisette',
                    'products': [
                        'Robe Satin AsymÃ©trique : 3 piÃ¨ces',
                        'Sac MatelassÃ© ChaÃ®ne DorÃ©e : 5 piÃ¨ces',
                        'Escarpins Bout Rond : 4 piÃ¨ces',
                        'Collier Perles Signature : 6 piÃ¨ces',
                        'Ballerines Cuir Nude : 6 piÃ¨ces',
                        'Tailleur Tweed Iconique : 2 piÃ¨ces',
                        'Manteau BouclÃ© Long : 1 piÃ¨ce'
                    ]
                }
            }
            
            detected_location = None
            for loc_key in location_stocks.keys():
                if loc_key in query_lower:
                    detected_location = loc_key
                    break
            
            if detected_location:
                stock_info = location_stocks[detected_location]
                base_response += f"""
    **Stock disponible Ã  {stock_info['name']} :**

    Voici notre inventaire complet dans cette boutique :
    """
                for product in stock_info['products']:
                    base_response += f"â€¢ {product}\n"
                
                base_response += "\nğŸ“ Pour rÃ©server un article ou obtenir plus d'informations, contactez directement la boutique."
            else:
                base_response += """
    **Nos stocks sont mis Ã  jour en temps rÃ©el dans nos 3 boutiques :**

    â€¢ **Paris Cambon** : Notre flagship avec la collection complÃ¨te
    â€¢ **Lyon Presqu'Ã®le** : SÃ©lection premium et nouveautÃ©s  
    â€¢ **Cannes Croisette** : Collection saisonniÃ¨re et piÃ¨ces exclusives

    ğŸ’¡ PrÃ©cisez une boutique (Paris, Lyon ou Cannes) pour voir le dÃ©tail des stocks."""
        
        else:
            # Pour toutes les autres intentions, utiliser les templates
            templates = response_templates.get(prediction.intent, ["Voici ce que j'ai trouvÃ© pour vous :"])
            base_response = random.choice(templates)
        
        # Affichage enrichi des produits
        if products and prediction.intent in ['product_search', 'price_inquiry', 'style_recommendation']:
            base_response += "\n"
            
            for i, product in enumerate(products[:3], 1):
                # Informations essentielles
                name = product.get('name', 'Produit')
                price = product.get('price', 0)
                currency = product.get('currency', 'EUR')
                
                # Informations contextuelles
                materials = product.get('materials', [])
                colors = product.get('colors', [])
                occasions = product.get('occasions', [])
                
                # Score de pertinence
                similarity = product.get('similarity_score', 0)
                
                # Construction de la description
                product_line = f"\n{i}. **{name}** - {price} {currency}"
                
                # Ajout d'informations contextuelles
                details = []
                if materials:
                    details.append(f"MatiÃ¨res: {', '.join(materials[:2])}")
                if colors:
                    details.append(f"Couleurs: {', '.join(colors[:2])}")
                if occasions:
                    details.append(f"Occasions: {', '.join(occasions[:2])}")
                
                if details:
                    product_line += f"\n   ğŸ“ {' â€¢ '.join(details)}"
                
                # Indicateur de pertinence
                if similarity > 0.7:
                    product_line += " â­ *Excellent match*"
                elif similarity > 0.5:
                    product_line += " âœ¨ *Bon match*"
                
                base_response += product_line
        
        elif prediction.intent in ['product_search', 'style_recommendation'] and not products:
            # Cas oÃ¹ aucun produit n'est trouvÃ©
            base_response += "\n\nJe n'ai pas trouvÃ© de produit correspondant exactement Ã  votre recherche."
            base_response += "\nPourriez-vous prÃ©ciser vos prÃ©fÃ©rences (couleur, occasion, budget) ?"
        
        # Informations contextuelles enrichies
        if prediction.entities:
            context_info = []
            
            # EntitÃ©s importantes Ã  mettre en valeur
            priority_entities = ['color', 'occasion', 'material', 'product_type', 'price']
            
            for entity_type in priority_entities:
                if entity_type in prediction.entities:
                    values = prediction.entities[entity_type]
                    entity_display = {
                        'color': 'ğŸ¨ Couleur',
                        'occasion': 'âœ¨ Occasion', 
                        'material': 'ğŸ§µ MatiÃ¨re',
                        'product_type': 'ğŸ‘œ Type',
                        'price': 'ğŸ’° Budget'
                    }
                    
                    display_name = entity_display.get(entity_type, entity_type.title())
                    context_info.append(f"{display_name}: {', '.join(values)}")
            
            if context_info:
                base_response += f"\n\nğŸ” **CritÃ¨res dÃ©tectÃ©s:** {' â€¢ '.join(context_info)}"
        
        # Suggestions proactives
        if prediction.intent == 'product_search' and products:
            base_response += "\n\nğŸ’¡ *Conseil: Dites-moi \"plus d'infos sur le produit 1\" pour obtenir des dÃ©tails complets.*"
        elif prediction.intent == 'style_recommendation':
            base_response += "\n\nğŸ‘— *Astuce: Je peux aussi vous conseiller des accessoires assortis !*"
        elif prediction.intent == 'stock_check' and products:
            # Informations de stock si disponibles
            stock_info = []
            for product in products[:2]:
                stock_locations = product.get('stock_locations', {})
                if stock_locations:
                    total_stock = sum(stock_locations.values())
                    if total_stock > 0:
                        stock_info.append(f"{product['name']}: {total_stock} piÃ¨ces disponibles")
                    else:
                        stock_info.append(f"{product['name']}: Sur commande")
            
            if stock_info:
                base_response += f"\n\nğŸ“¦ **Stock:** {' â€¢ '.join(stock_info)}"
        
        # Appel Ã  l'action minimal et discret
        confidence = prediction.confidence
    
        if confidence > 0.8:
            base_response += "\n\nâ“ Y a-t-il autre chose que je puisse vous proposer ?"
        
        return base_response

    def save_model(self, filepath: str):
        """Sauvegarde robuste du modÃ¨le"""
        try:
            import pickle
            model_data = {
                'intent_classifier': self.intent_classifier,
                'vectorizer': self.intent_classifier.vectorizer,
                'label_encoder': self.intent_classifier.label_encoder,
                'products_df': self.semantic_search.products_df,
                'use_semantic': self.semantic_search.use_semantic
            }
            
            with open(filepath, 'wb') as f:
                pickle.dump(model_data, f)
            print(f"âœ… ModÃ¨le sauvegardÃ©: {filepath}")
        except Exception as e:
            print(f"âŒ Erreur sauvegarde: {e}")
    
    def load_model(self, filepath: str):
        """Chargement robuste du modÃ¨le"""
        try:
            import pickle
            with open(filepath, 'rb') as f:
                model_data = pickle.load(f)
            
            self.intent_classifier = model_data['intent_classifier']
            self.semantic_search.products_df = model_data['products_df']
            self.semantic_search.use_semantic = model_data.get('use_semantic', False)
            
            print(f"âœ… ModÃ¨le chargÃ©: {filepath}")
        except Exception as e:
            print(f"âŒ Erreur chargement: {e}")
            raise

# Test principal 
if __name__ == "__main__":
    print("ğŸš€ CHATBOT ULTRA-OPTIMISÃ‰ 2025")
    print("ğŸ¯ Validation croisÃ©e + Recherche hybride robuste + Gestion d'erreurs")
    
    chatbot = OptimizedFashionChatbot()
    
    try:
        # EntraÃ®nement avec gestion d'erreur robuste
        print("\nğŸ“š Phase d'entraÃ®nement...")
        results = chatbot.train_full_pipeline(
            'training_data.json',  # Chemins relatifs
            'products.json'
        )
        
        if results['status'] == 'optimized_success':
            print(f"\nğŸ‰ ENTRAÃNEMENT RÃ‰USSI !")
            print(f"ğŸ¯ PrÃ©cision CV: {results['intent_classification']['cv_accuracy']:.1%}")
            print(f"ğŸ” Produits indexÃ©s: {results['products_indexed']}")
            print(f"ğŸ”® Recherche sÃ©mantique: {'âœ… ActivÃ©e' if results['semantic_search_enabled'] else 'ğŸ“ Textuelle uniquement'}")
            
            # Tests variÃ©s avec gestion d'erreur
            test_queries = [
                "Bonjour !",
                "",  # Test cas vide
                "Je cherche un sac noir pour le bureau",
                "Avez-vous des chaussures confortables ?",
                "Combien coÃ»te le tailleur tweed ?",
                "Stock disponible Ã  Paris ?",
                "Que me conseillez-vous pour un mariage ?",
                "Comment entretenir le cuir d'agneau ?",
                "sdkfjhsdkjfh",  # Test cas incomprÃ©hensible
                "Merci beaucoup, au revoir !",
                "Des bijoux en perles ?"
            ]
            
            print("\nğŸ§ª TESTS VARIÃ‰S:")
            for i, query in enumerate(test_queries, 1):
                print(f"\n--- Test {i} ---")
                result = chatbot.process_query(query)
                
                if result['success']:
                    print(f"ğŸ’¬ '{query}'")
                    print(f"ğŸ¯ Intent: {result['intent']} (confiance: {result['confidence']:.1%})")
                    
                    if result['entities']:
                        print(f"ğŸ·ï¸  EntitÃ©s: {result['entities']}")
                    
                    if result['recommended_products']:
                        print(f"ğŸ›ï¸  Produits trouvÃ©s: {len(result['recommended_products'])}")
                    
                    # RÃ©ponse tronquÃ©e pour l'affichage
                    response_preview = result['response'][:100]
                    if len(result['response']) > 100:
                        response_preview += "..."
                    print(f"ğŸ’¡ RÃ©ponse: {response_preview}")
                    
                    # Debug info
                    debug = result.get('debug_info', {})
                    print(f"ğŸ”§ Debug: Query processÃ©e='{debug.get('processed_query', 'N/A')[:30]}...', Produits={debug.get('products_found', 0)}")
                else:
                    print(f"âŒ Erreur: {result.get('error', 'Inconnue')}")
                    print(f"ğŸ”„ Fallback: {result.get('fallback_response', 'Aucun')}")
            
            # Sauvegarde du modÃ¨le
            print(f"\nğŸ’¾ Sauvegarde du modÃ¨le...")
            chatbot.save_model('fashion_chatbot_optimized.pkl')
            
        else:
            print(f"âŒ Ã‰CHEC ENTRAÃNEMENT: {results.get('error', 'Erreur inconnue')}")
            
    except Exception as e:
        print(f"âŒ Erreur gÃ©nÃ©rale: {e}")
        import traceback
        traceback.print_exc()